# app.py
# -*- coding: utf-8 -*-

import os
import streamlit as st
from dotenv import load_dotenv

from rag_core import create_rag_pipeline, get_rag_response

# è¯»å– .env
load_dotenv()

# ------------------ æ¨¡å‹é…ç½® ------------------
LLM_CANDIDATES = [
    ("gpt-4", "OpenAI GPT-4"),
    ("deepseek-v3", "DeepSeek V3"),
    ("deepseek-r1", "DeepSeek R1"),
]

# ------------------ é¡µé¢è®¾ç½® ------------------
st.set_page_config(page_title="AI æ–‡æ¡£é—®ç­”åŠ©æ‰‹", layout="wide")
st.title("ğŸ“„ AI æ–‡æ¡£é—®ç­”åŠ©æ‰‹")
st.caption("RAG + å¤šè½®è®°å¿† Â· å¼•ç”¨ç²¾ç¡®åˆ°æ–‡ä»¶ä¸åŸæ–‡ç‰‡æ®µ")

# ------------------ Session State ------------------
if "rag_session" not in st.session_state:
    # ä¿å­˜æ•´ä¸ª RAG ä¼šè¯ç›¸å…³å¯¹è±¡ä¸çŠ¶æ€
    st.session_state.rag_session = None
if "uploaded_file_names" not in st.session_state:
    st.session_state.uploaded_file_names = []
if "chat_history_view" not in st.session_state:
    # ä»…ç”¨äº UI å±•ç¤ºï¼ˆé—®é¢˜/ç­”æ¡ˆåˆ—è¡¨ï¼‰
    st.session_state.chat_history_view = []


# ------------------ ä¾§è¾¹æ ï¼šæ–‡ä»¶ & æ¨¡å‹ & æ§åˆ¶ ------------------
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    st.subheader("1ï¸âƒ£ ä¸Šä¼ æ–‡æ¡£")
    uploaded_files = st.file_uploader(
        "è¯·ä¸Šä¼  1ï½5 ä¸ªæ–‡ä»¶ï¼ˆPDF / TXT / DOCX / PPTX / MD / HTMLï¼‰",
        type=["pdf", "txt", "docx", "pptx", "md", "html", "htm"],
        accept_multiple_files=True,
    )

    st.subheader("2ï¸âƒ£ é€‰æ‹©æ¨¡å‹")
    model_map = dict(LLM_CANDIDATES)
    model_key = st.selectbox(
        "è¯·é€‰æ‹©ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹",
        options=[m[0] for m in LLM_CANDIDATES],
        format_func=lambda x: model_map[x],
    )

    col_a, col_b = st.columns(2)
    with col_a:
        build_clicked = st.button("ğŸš€ æ„å»º / é‡å»ºçŸ¥è¯†åº“", use_container_width=True)
    with col_b:
        clear_clicked = st.button("ğŸ§¹ æ¸…ç©ºä¼šè¯", use_container_width=True)

    if clear_clicked:
        st.session_state.chat_history_view = []
        # ä»…æ¸…ç©ºå¯¹è¯ï¼Œä¸åŠ¨å‘é‡åº“
        if st.session_state.rag_session and "memory" in st.session_state.rag_session:
            st.session_state.rag_session["memory"].clear()
        st.success("å·²æ¸…ç©ºå¯¹è¯ã€‚")

    if build_clicked:
        if not uploaded_files:
            st.error("â— è¯·å…ˆä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡æ¡£ã€‚")
        elif len(uploaded_files) > 5:
            st.error("âŒ æœ€å¤šåªèƒ½ä¸Šä¼  5 ä¸ªæ–‡ä»¶ã€‚")
        else:
            with st.spinner("â³ æ­£åœ¨å¤„ç†ä¸ç´¢å¼•æ–‡æ¡£ ..."):
                # ä¿å­˜æ–‡ä»¶åˆ° ./data
                os.makedirs("data", exist_ok=True)
                file_paths, names = [], []
                for f in uploaded_files:
                    p = os.path.join("data", f.name)
                    with open(p, "wb") as wf:
                        wf.write(f.getvalue())
                    file_paths.append(p)
                    names.append(f.name)

                try:
                    # âœ… ç°åœ¨ create_rag_pipeline è¿”å› 5 ä¸ªå¯¹è±¡
                    llm, vectorstore, retriever, memory, chain = create_rag_pipeline(
                        file_paths=file_paths,
                        model_key=model_key,
                    )
                    st.session_state.rag_session = {
                        "llm": llm,
                        "vectorstore": vectorstore,
                        "retriever": retriever,
                        "memory": memory,
                        "chain": chain,
                    }
                    st.session_state.uploaded_file_names = names
                    st.session_state.chat_history_view = []
                    st.success("âœ… çŸ¥è¯†åº“æ„å»ºæˆåŠŸï¼å¯ä»¥å¼€å§‹æé—®å•¦ã€‚")
                except Exception as e:
                    st.session_state.rag_session = None
                    st.error(f"æ„å»ºçŸ¥è¯†åº“æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")


# ------------------ ä¸»åŒºï¼šæ–‡ä»¶æ¸…å• + é—®ç­” ------------------
left, right = st.columns([2, 3])

with left:
    st.subheader("ğŸ“¦ å½“å‰çŸ¥è¯†åº“")
    if st.session_state.uploaded_file_names:
        for name in st.session_state.uploaded_file_names:
            st.markdown(f"- ğŸ“„ **{name}**")
    else:
        st.info("å°šæœªåŠ è½½æ–‡æ¡£ã€‚è¯·åœ¨å·¦ä¾§ä¸Šä¼ å¹¶æ„å»ºã€‚")

with right:
    st.subheader("ğŸ’¬ æé—®åŒºï¼ˆæ”¯æŒè¿ç»­è¿½é—®ï¼‰")

    disabled = st.session_state.rag_session is None
    # æ›´é¡ºæ‰‹çš„è¡¨å•ï¼Œå›è½¦å³æäº¤
    with st.form("ask_form", clear_on_submit=True):
        query = st.text_input(
            "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š",
            placeholder="ä¾‹å¦‚ï¼šâ€˜è¿™ä»½æ–‡æ¡£çš„å…³é”®ç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿè¯·ç»™å‡ºåŸæ–‡å‡ºå¤„ã€‚â€™",
            disabled=disabled,
        )
        submitted = st.form_submit_button("ğŸ” æäº¤é—®é¢˜", disabled=disabled, use_container_width=True)

    # å±•ç¤ºå†å²å¯¹è¯
    if st.session_state.chat_history_view:
        st.markdown("#### ğŸ—‚ï¸ å†å²å¯¹è¯")
        for qa in st.session_state.chat_history_view:
            st.markdown(f"**ä½ ï¼š** {qa['q']}")
            st.markdown(f"**åŠ©æ‰‹ï¼š** {qa['a']}")
            if qa.get("refs"):
                with st.expander("ğŸ“š å‚è€ƒèµ„æ–™ï¼ˆå±•å¼€æŸ¥çœ‹åŸæ–‡ç‰‡æ®µï¼‰"):
                    for i, r in enumerate(qa["refs"], 1):
                        st.markdown(f"**[{i}] {r['source']}**")
                        if r.get("path"):
                            st.caption(r["path"])
                        st.code(r["snippet"])

    # å¤„ç†æœ¬æ¬¡æé—®
    if submitted and query:
        with st.spinner("ğŸ¤– æ­£åœ¨æ£€ç´¢ä¸ç”Ÿæˆ ..."):
            try:
                chain = st.session_state.rag_session["chain"]
                result = get_rag_response(query, chain)

                # UI å±•ç¤º
                st.markdown("### ğŸ¤– æ¨¡å‹çš„å›ç­”")
                st.write(result["answer"])

                st.markdown("### ğŸ“š å¼•ç”¨æ¥æºï¼ˆå¯å±•å¼€æŸ¥çœ‹åŸæ–‡ï¼‰")
                if result["references"]:
                    for i, r in enumerate(result["references"], 1):
                        with st.expander(f"[{i}] {r['source']}"):
                            if r.get("path"):
                                st.caption(r["path"])
                            st.code(r["snippet"])
                else:
                    st.info("æœªæ£€ç´¢åˆ°å¯ç”¨çš„ç›´æ¥å¼•ç”¨ã€‚")

                # è®°å½•åˆ°å¯¹è¯å†å²ï¼ˆç”¨äºå³ä¸Šæ–¹å†å²åŒºå±•ç¤ºï¼‰
                st.session_state.chat_history_view.append(
                    {"q": query, "a": result["answer"], "refs": result["references"]}
                )
            except Exception as e:
                st.error(f"å›ç­”ç”Ÿæˆå¤±è´¥ï¼š{e}")
